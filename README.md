# PRISM â€” Personalized Retrieval-based Intelligent Study Mentor

PRISM is an AI-powered learning system that helps users **understand knowledge from books and long-form content without reading everything themselves**.

The system retrieves relevant information from stored knowledge and generates **personalized explanations** based on the userâ€™s learning style and level.

This project is built as a **real system**, not a demo, and demonstrates retrieval, memory, and reasoning using Qdrant and a modern LLM.

---

## ğŸš© Problem Statement

Many people want to learn from books but struggle with:
- Lack of reading habits
- Time constraints
- Different learning preferences

Books contain valuable knowledge, but the format is not always accessible to everyone.

**PRISM addresses this by:**
- Extracting knowledge from books
- Storing it in a searchable memory
- Explaining concepts in a personalized way using AI

---

## ğŸ’¡ Solution Overview

PRISM uses a **Retrieval-Augmented Generation (RAG)** approach:

1. Book content is stored as semantic embeddings
2. Relevant knowledge is retrieved based on the user query
3. An AI agent builds a personalized explanation prompt
4. A language model generates a human-friendly explanation

This ensures answers are **grounded in real content**, not hallucinated.

---

## ğŸ§  System Architecture

The system is divided into the following layers:

- **Data Ingestion**: Load, chunk, and embed book text
- **Vector Memory**: Store embeddings in Qdrant
- **Retrieval & Agent Reasoning**: Fetch relevant context and personalize explanations
- **LLM Generation**: Generate natural language explanations

Detailed architecture is documented in [`ARCHITECTURE.md`](ARCHITECTURE.md).

---

## ğŸ§© Key Technologies

- **Python**
- **Qdrant** â€” Vector database for semantic search and memory
- **SentenceTransformers** â€” Text embeddings
- **Gemini 2.5 Flash** â€” Language model (free tier)
- **Docker** â€” Running Qdrant locally

---

## ğŸ§  Why Qdrant is Critical

Qdrant is the backbone of PRISMâ€™s memory system.

It enables:
- Semantic search over book knowledge
- Fast retrieval of relevant concepts
- Separation of memory from reasoning
- Scalable, production-like architecture

Without Qdrant, the system would degrade into a simple prompt-based chatbot.

---

## ğŸ“‚ Project Structure

prism/
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ load_book.py
â”‚ â”œâ”€â”€ chunk_book.py
â”‚ â”œâ”€â”€ embed_chunks.py
â”‚ â”œâ”€â”€ store_in_qdrant.py
â”‚ â”œâ”€â”€ search_qdrant.py
â”‚ â”œâ”€â”€ agent_explain.py
â”‚ â””â”€â”€ llm_runner.py
â”‚
â”‚â”€â”€ data/
â”‚ â””â”€â”€ books/
â”‚ â””â”€â”€ atomic_habits.txt
â”‚
â”‚â”€â”€ ARCHITECTURE.md
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone <repository-url>
cd prism
```

2ï¸âƒ£ Create and activate virtual environment
```bash
python -m venv venv
venv\Scripts\activate
```

3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Start Qdrant (Docker)
```bash
docker run -d -p 6333:6333 qdrant/qdrant
```

Open dashboard:
```bash
http://localhost:6333/dashboard
```

ğŸ” Environment Variables
Create a .env file in the project root:
```ini
GEMINI_API_KEY=your_api_key_here
```
Ensure .env is added to .gitignore

â–¶ï¸ Running the System
Load data into Qdrant
```bash
python src/store_in_qdrant.py
```

Run the AI Tutor
```bash
python src/llm_runner.py
```

ğŸ§ª Example Query
```rust
How do habits become part of identity?
```
The system retrieves relevant book content and explains it in a story-based style for beginners.

âš ï¸ Limitations & Ethics

Limitations
- Depends on quality of source text
- Free-tier LLM availability may vary

Ethics
- No personal user data stored
- Transparent retrieval-based explanations
- Reduced hallucinations via grounding

ğŸš€ Future Enhancements
- Audio-based explanations
- Adaptive difficulty levels
- User learning progress memory
- Multi-book support
- Web or mobile interface

ğŸ“Œ Summary
- PRISM demonstrates a complete AI system combining:
- Vector memory
- Semantic search
- Agent-based reasoning
- LLM-powered explanations
- It is designed to be extensible, explainable, and aligned with real-world AI system principles.